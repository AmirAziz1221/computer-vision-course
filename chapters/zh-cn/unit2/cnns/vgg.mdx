# 用于大规模图像识别的超深卷积网络 (2014)

## 引言

VGG 网络架构由牛津大学视觉几何组（Visual Geometry Group）的 Karen Simonyan 和 Andrew Zisserman 于 2014 年提出，因此以该小组的缩写 VGG 命名。该模型在当时诸多模型中实现了显著的性能提升，并在 2014 年的 ImageNet 挑战赛（亦称 ILSVRC）中表现优异。

## VGG 网络架构

- 输入图像尺寸为 224x224 像素。
- 卷积核的尺寸为 (3,3)，最大池化窗口的尺寸为 (2,2)。
- 各卷积层通道数依次递增：64 -> 128 -> 256 -> 512 -> 512。
- VGG16 包含 16 个隐藏层，其中包括 13 个卷积层和 3 个全连接层。
- VGG19 包含 19 个隐藏层，其中包括 16 个卷积层和 3 个全连接层。

## 关键对比

- 相较于当时的其他先进（SOTA）网络，VGG（16 或 19 层）的深度显著增加。例如，ILSVRC 2012 的冠军模型 AlexNet 仅有 8 层。
- 采用多个具有 ReLU 激活函数的小型 (3X3) 感受野滤波器，而非单个大型 (7X7 或 11X11) 滤波器，能够更有效地学习复杂的特征。此外，较小的滤波器也降低了每层的参数数量，并在网络中引入了更多的非线性。
- 采用多尺度训练和推理方法。每张图像都经过多轮不同尺度的训练，以确保网络能够捕获不同尺寸下的特征。
- VGG 网络的稳定性和简洁性使其易于扩展或修改，从而为后续改进奠定了基础。

## PyTorch 示例

以下是 VGG19 的 PyTorch 实现。

```python
import torch.nn as nn


class VGG19(nn.Module):
    def __init__(self, num_classes=1000):
        super(VGG19, self).__init__()

        # 特征提取层：卷积层和池化层
        self.feature_extractor = nn.Sequential(
            nn.Conv2d(
                3, 64, kernel_size=3, padding=1
            ),  # 3 个输入通道，64 个输出通道，3x3 卷积核，1 填充
            nn.ReLU(),
            nn.Conv2d(64, 64, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2),  # 2x2 卷积核，步长为 2 的最大池化
            nn.Conv2d(64, 128, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.Conv2d(128, 128, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2),
            nn.Conv2d(128, 256, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.Conv2d(256, 256, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.Conv2d(256, 256, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.Conv2d(256, 256, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2),
            nn.Conv2d(256, 512, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.Conv2d(512, 512, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.Conv2d(512, 512, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.Conv2d(512, 512, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2),
            nn.Conv2d(512, 512, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.Conv2d(512, 512, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.Conv2d(512, 512, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.Conv2d(512, 512, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2),
        )

        # 池化层
        self.avgpool = nn.AdaptiveAvgPool2d(output_size=(7, 7))

        # 用于分类的全连接层
        self.classifier = nn.Sequential(
            nn.Linear(512 * 7 * 7, 4096),  # 512 个通道，最大池化后 7x7 空间维度
            nn.ReLU(),
            nn.Dropout(0.5),  # Dropout 层，dropout 概率为 0.5
            nn.Linear(4096, 4096),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(4096, num_classes),  # 输出层，输出单元数为 'num_classes'
        )

    def forward(self, x):
        x = self.feature_extractor(x)  # 将输入传递到特征提取层
        x = self.avgpool(x)  # 通过池化层传递数据
        x = x.view(x.size(0), -1)  # 展平输出，用于全连接层
        x = self.classifier(x)  # 将展平的输出传递到分类层
        return x
```
