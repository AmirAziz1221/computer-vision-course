# ResNet (残差网络)

人们一度认为，增加神经网络的层数能够提升模型性能，因此层数越多的神经网络效果越好。

随着网络深度加深，所提取的特征也随之更加丰富，例如 VGG16 和 VGG19 就证明了这一点。

由此产生了一个问题：“训练深度学习模型是否就像堆积木一样简单？”
为了解答这个问题，首先需要解决梯度消失问题，而归一化初始化和中间归一化层为此提供了解决方案。

然而，新的问题随之出现：退化问题。随着神经网络变得更深，模型准确率达到饱和，并迅速下降。一项针对浅层和深层普通网络(Plain Networks)的对比实验表明，更深的模型表现出更高的训练和测试误差，这表明在有效训练更深层架构方面存在根本性的挑战。这种退化并非源于过拟合，而是因为当网络加深时，训练误差反而增加。增加的层并没有逼近恒等函数。

<img src="https://i.sstatic.net/xDLez.jpg" alt="Degradation-error" width="512" height="512">

ResNet 通过残差连接释放了深度网络的潜力，与之前的架构相比，显著提高了准确率。

## ResNet 架构

- 一个残差块。来源：ResNet 论文
![residual](https://huggingface.co/datasets/hf-vision/course-assets/blob/main/ResnetBlock.png)

ResNet 引入了残差学习(Residual Learning)的概念，它允许网络学习残差（即，学习到的表示与输入之间的差异），而不是直接学习输入到输出的映射。这是通过跳跃连接（skip connections，或称捷径连接(Shortcut Connections)）实现的。

下面我们来详细分析一下：

#### 1. 基本构建块：残差块

在一个典型的神经网络层中，目标是学习一个映射 F(x)，其中 x 是输入，F 是网络应用的变换。如果没有残差学习，层中的变换为：y = F(x)。在 ResNet 中，网络并非直接学习 F(x)，而是被设计为学习残差 R(x)，其中：R(x) = F(x) − x。因此，残差块中的变换可以写成：y = F(x) + x。

这里，x 是残差块的输入，F(x) 是该块堆叠层的输出（通常是卷积、批量归一化和 ReLU）。恒等映射 x 直接加到 F(x) 的输出上（通过跳跃连接）。因此，该块学习的是残差 R(x) = F(x)，最终输出是 F(x) + x。与原始映射相比，这种残差函数更容易优化。如果最优变换接近于恒等变换（即，不需要变换），网络可以很容易地将 F(x) 设置为接近于 0，以便直接传递输入。

* ResNet 的构建块如图片所示，来源 ResNet 论文。

![resnet_building_block](https://huggingface.co/datasets/hf-vision/course-assets/resolve/main/ResnetBlock.png)

#### 2. 学习残差与梯度流

ResNet 在极深网络中表现出色的主要原因是反向传播过程中改进的梯度流。让我们从数学角度分析反向传播过程。假设有一个残差块 y = F(x) + x。当通过链式法则计算梯度时，需要计算损失 𝐿 相对于输入 x 的导数。对于一个标准块（没有残差），梯度为：

`∂x/∂L = ∂F(x)/∂L * ∂F(x)/∂x`

然而，对于残差块，其中 y = F(x) + x，梯度变为：

`∂L/∂x = ∂L/∂F(x) * ∂F(x)/∂x + ∂L/∂F(x) ⋅1`

请注意，现在的梯度计算中多出了一项 1。这意味着每一层的梯度都有一条直接返回到早期层的路径，从而改善了梯度流并减少了梯度消失的可能性。梯度更容易地通过网络流动，从而允许更深的网络在没有退化的情况下进行训练。

#### 3. 为什么现在可以实现更深的网络：

ResNet 使得训练具有数百甚至数千层的网络成为可能。以下是更深的网络能够从中受益的原因：

* 恒等捷径连接(Identity Shortcut Connections)：捷径连接执行恒等映射，其输出被添加到堆叠层的输出中。恒等捷径连接既不增加额外的参数，也不增加计算复杂度。这些连接绕过层，为信息流创建直接路径，并且它们使神经网络能够学习残差函数(F)。
* 更好的梯度流：如前所述，残差有助于梯度在反向传播期间更好地传播，从而解决了极深网络中的梯度消失问题。
* 更易于优化：通过学习残差，网络本质上是将学习过程分解为更简单、增量的步骤。对于网络而言，学习残差 R(x) = F(x) − x 比直接学习 F(x) 更容易，尤其是在极深的网络中。

### 总结：

我们可以得出结论：ResNet 网络 -> 普通网络 + 捷径连接！

对于运算\(F(x) + x\)，\(F(x)\)和\(x\)应该具有相同的维度。
ResNet 采用两种技术来实现这一点：

- 零填充捷径(Zero-padding shortcuts)：它使用零值填充通道，保持维度，且不会引入额外的可学习参数。
- 投影捷径(Projection shortcuts)：它在必要时使用 1x1 卷积来调整维度，这会涉及一些额外的可学习参数。

在更深的 ResNet 架构中，如 ResNet 50、101 和 152，采用了一种专门的“瓶颈构建块(Bottleneck building block)”，以控制参数复杂性，并在实现更深层次学习的同时保持效率。

## ResNet 代码

### 在 ImageNet 上预训练的深度残差网络

下面展示了如何使用 transformers 库加载带有图像分类头的预训练 ResNet。
```python
from transformers import ResNetForImageClassification

model = ResNetForImageClassification.from_pretrained("microsoft/resnet-50")

model.eval()
```

所有预训练模型都要求输入图像以类似的方式进行归一化，即形状为（3 x H x W）的 3 通道 RGB 图像小批量，其中 H 和 W 预计至少为 224。图像必须加载到 [0, 1] 范围内，然后使用 mean = [0.485, 0.456, 0.406] 和 std = [0.229, 0.224, 0.225] 进行归一化。

这是一个示例执行。此示例可在 [Hugging Face 文档](https://huggingface.co/docs/transformers/v4.18.0/en/model_doc/resnet)中找到。

```python
from transformers import AutoFeatureExtractor, ResNetForImageClassification
import torch
from datasets import load_dataset

dataset = load_dataset("huggingface/cats-image")
image = dataset["test"]["image"][0]

feature_extractor = AutoFeatureExtractor.from_pretrained("microsoft/resnet-50")
model = ResNetForImageClassification.from_pretrained("microsoft/resnet-50")

inputs = feature_extractor(image, return_tensors="pt")

with torch.no_grad():
    logits = model(**inputs).logits

# model predicts one of the 1000 ImageNet classes
predicted_label = logits.argmax(-1).item()
print(model.config.id2label[predicted_label])
```

## 参考文献

- [PyTorch docs](https://pytorch.org/hub/pytorch_vision_resnet/)
- [ResNet: Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)

- [Resnet Architecture Source: ResNet Paper](https://arxiv.org/abs/1512.03385)
- [Hugging Face Documentation on ResNet](https://huggingface.co/docs/transformers/en/model_doc/resnet)

